[TOC]



# Lecture 1: Asymptotic Algorithm Analysis



## Objective:

- [ ] Understand best, worst, and average cases
- [ ] Understand Big-Oh, Big-Omega, Big-Theta notations
- [ ] Know how to analyze time complexity of a program



## Best, Worst, Average Cases

- **Best case:** å¯¹åº”ideal input, æ‰€éœ€è¦çš„æœ€å°‘çš„number of steps
- **Worst case:** å¯¹åº”most difficult input, æ‰€éœ€è¦çš„æœ€å¤šçš„number of steps
- **Average case:** å¯¹åº”random inputs, æ‰€éœ€è¦çš„å¹³å‡number of steps

*ğŸ‘€æ³¨æ„ï¼š*

> å¦‚æœè¯´â€œæˆ‘çš„ç¨‹åºåœ¨n = 1ï¼ˆsingle inputï¼‰çš„æ—¶å€™æ˜¯best caseå› ä¸ºè¿™æ˜¯æœ€å¿«çš„â€ è¿™å¥è¯æ˜¯âŒçš„
>
> å› ä¸ºbest caseçš„æ„æ€æ˜¯ä¸€ä¸ªåœ¨å¯¹äºä»»ä½•size $n$çš„inputæ—¶çš„ä¸€ä¸ªä»£ä»·æœ€ä½çš„<u>special input</u>



### â“åœ¨åˆ†æä¸€ä¸ªç®—æ³•çš„æ—¶å€™åˆ†æå“ªç§caseâ“

> é€šå¸¸ç”¨average case / worst caseã€‚Average caseçœ‹èµ·æ¥æ¯”è¾ƒå…¬å¹³ï¼Œä½†æ˜¯éœ€è¦çŸ¥é“distribution of inputs, æ¯”è¾ƒéš¾ç¡®å®šã€‚Worst caseæ¯”è¾ƒå®¹æ˜“åˆ†æï¼Œè€Œä¸”ç»™äº†upper bound



### â“å¦‚ä½•åˆ†æç®—æ³•çš„å¤æ‚åº¦â“

#### **I. Ignore constant factors**

1. æ¯”è¾ƒå®¹æ˜“
2. Constants depend on architecture, compiler, etc.
3. Lose very little predictive power

#### II. Focus on running time for large input size $n$

1. Scaling is very importantï¼Œå› ä¸ºä¸€ä¸ªç®—æ³•åœ¨inputå°‘è·Ÿå¤šçš„æ—¶å€™å·®åˆ«å¯èƒ½ä¼šå¾ˆå¤§

2. We compare the runtime of two algorithm when $n$ is very large.

   > $1000log_2n$ is better than $0.001n$

****



## Asymptotic Analysis: Big-Oh

- **å®šä¹‰ï¼š**å¯¹äºä¸€ä¸ªå€¼éè´Ÿçš„æ–¹ç¨‹ $T(n)$ æ¥è¯´ï¼Œå¦‚æœ<u>å­˜åœ¨</u>ä¸¤ä¸ªæ­£çš„å¸¸æ•° $c$ å’Œ $n_0$ï¼Œ ä½¿å¾—$T(n)\le cf(n)$ for all $n > n_0$, é‚£ä¹ˆæ–¹ç¨‹$T(n)$ å°±æ˜¯åœ¨é›†åˆ $O(f(n))$é‡Œ
- **å«ä¹‰ï¼š**å½“æ•°æ®è¶³å¤Ÿå¤§æ—¶$(n\ge n_0)$æ—¶ï¼Œè¯¥ç®—æ³•æ‰§è¡Œçš„æ­¥éª¤æ•°æ€»<u>å°äº</u>$cf(n)$ å¯¹äºbest/ average/ worst case.



### Big-Oh Notation

Big-oh notation indicates an upper bound, é€šå¸¸æˆ‘ä»¬å¯»æ‰¾==tightest upper bound==

#### ğŸ‘€ I. A sufficient condition of Big-Oh

<img src="/Users/michaelxu/Library/Application Support/typora-user-images/image-20200911194051559.png" alt="image-20200911194051559" style="zoom:50%;" />



#### II. Rules of Big-Oh

<img src="/Users/michaelxu/Library/Application Support/typora-user-images/image-20200926193345039.png" alt="image-20200926193345039" style="zoom:50%;" />

<img src="/Users/michaelxu/Library/Application Support/typora-user-images/image-20200926193404044.png" alt="image-20200926193404044" style="zoom:50%;" />



#### III. A Few Results about Common Functions

<img src="/Users/michaelxu/Library/Application Support/typora-user-images/image-20200926193518935.png" alt="image-20200926193518935" style="zoom:50%;" />

ğŸ‘€**ç»ƒä¹ ï¼š**

<img src="/Users/michaelxu/Library/Application Support/typora-user-images/image-20200926193650699.png" alt="image-20200926193650699" style="zoom:50%;" />

****



## Relative of Big-Oh: 1. Big-Omega

- **å®šä¹‰ï¼š** å¯¹äºä¸€ä¸ªå€¼éè´Ÿçš„æ–¹ç¨‹ $T(n)$ æ¥è¯´ï¼Œå¦‚æœ<u>å­˜åœ¨</u>ä¸¤ä¸ªæ­£çš„å¸¸æ•° $c$ å’Œ $n_0$ï¼Œ ä½¿å¾—$T(n)\ge cg(n)$ for all $n > n_0$, é‚£ä¹ˆæ–¹ç¨‹$T(n)$ å°±æ˜¯åœ¨é›†åˆ $\Omega (g(n))$é‡Œ
- **å«ä¹‰ï¼š**å¯¹äºæ‰€æœ‰è¶³å¤Ÿå¤§çš„æ•°æ®ï¼ˆ$n > n_0$), è¯¥ç®—æ³•å§‹ç»ˆéœ€è¦æ¯”$cg(n)$æ›´å¤šçš„æ­¥éª¤

âš ï¸ Big-Omega gives a lower bound, we usually want ==the greatest lower bound==

> â“What is the big-omega notation for $T(n) = c_1(n^2) + c_2(n)$â“
>
> Answerï¼š$T(n) = O(n^2) = \Omega (n^2)$



# Relative of Big-Oh: 2. Big-Theta

- **å®šä¹‰ï¼š**å¦‚æœ$T(n)$åœ¨é›†åˆ$O(g(n))$ä»¥åŠ$\Omega(g(n))$ä¸­, é‚£ä¹ˆç§°$T(n)$åœ¨é›†åˆ$\theta(g(n))$ä¸­ã€‚
  - æ•°å­¦å«ä¹‰ï¼šå­˜åœ¨ä¸‰ä¸ªæ­£çš„å¸¸æ•°ï¼Œ$c1, c2, n0$ ä½¿å¾—å¯¹äºæ‰€æœ‰çš„$n > n_0$ ,éƒ½æœ‰$c_1g(n) \le T(n) \le c_2g(n)$

ğŸŒ°

<img src="/Users/michaelxu/Library/Application Support/typora-user-images/image-20201026191344150.png" alt="image-20201026191344150" style="zoom:40%;" />

